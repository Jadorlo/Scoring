{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FONCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction de Création d'une Clef de Répartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tire une clef de repartition (en %) de manière aleatoire en fonction du nombre de classe voulue et d'une valeur planché de % de classe\n",
    "# !!!! UN NOMBRE DE CLASSES TROP GRAND PEUT ETRE PARADOXAL AVEC LA VALEUR PLANCHé !!!! \n",
    "# Exemple : 10 classes avec une valeur planché est de 15% -> 15%*10 = 150% donc impossible\n",
    "def clef_repartition_random(nb_classe,v_planche):\n",
    "    clef_repartition = [v_planche] * nb_classe\n",
    "    somme_restant = 100 - sum(clef_repartition)\n",
    "\n",
    "    for i in range(nb_classe):\n",
    "        if somme_restant <= 0:\n",
    "            break\n",
    "        max_val = somme_restant + clef_repartition[i]\n",
    "        nouvelle_valeur = random.randint(v_planche, max_val)\n",
    "        somme_restant -= (nouvelle_valeur - clef_repartition[i])\n",
    "        clef_repartition[i] = nouvelle_valeur\n",
    "    \n",
    "    clef_repartition[-1] += somme_restant\n",
    "    random.shuffle(clef_repartition)\n",
    "    \n",
    "    return clef_repartition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction de Répartition Cumulative des Valeurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Donne la repartition des individus en fonction d'une clef de repartition et la taille de l'échantillion\n",
    "# Cette repartition est sous forme d'une liste donnant les index de bornes des différentes classes\n",
    "def repartition_cumulative(clef_repartition, taille_serie) :\n",
    "    repartition = [round(taille_serie * x / 100) for x in clef_repartition]\n",
    "\n",
    "    # Avec les valeurs arrondies, on peut se retrouver avec des différences de +-1, on rectifie le resultat de manière arbitraire\n",
    "    while sum(repartition) > taille_serie :\n",
    "        repartition[-1] -= 1\n",
    "    \n",
    "    while sum(repartition) < taille_serie :\n",
    "        repartition[-1] += 1\n",
    "\n",
    "    cumulative_repartition = [sum(repartition[:i+1]) for i in range(len(repartition))]\n",
    "    return cumulative_repartition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction donnant l'Encadrement des Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Donne une liste avec les valeurs des encadements en fonction de la repartition cumulative et des valeurs de la serie\n",
    "def encadrements_classe(repartition_cumulative, serie) :\n",
    "    valeur = serie.iloc[[i - 1 for i in repartition_cumulative]].tolist()\n",
    "    valeur = [min(serie)]+ valeur \n",
    "    return valeur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction de Subsitution des Valeurs de la Serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplace les valeurs quantitatives d'une serie par des classes selon un encadrement donné dans une liste\n",
    "# Pas parfaitement optimisé car il transforme toute la série puis revient pour complter les NaN a cause de la valeur maximum qui n'est pas prit en compte cause de la borne exclue \n",
    "\n",
    "def substitutions_valeurs1(serie, bins):\n",
    "    # Création des labels en fonction des intervalles\n",
    "    labels = [f\"[{bins[i]};{bins[i+1]}[\" for i in range(len(bins)-2)]\n",
    "    # Dernier intervalle inclut la borne droite\n",
    "    labels.append(f\"[{bins[-2]};{bins[-1]}]\")  \n",
    "    \n",
    "    # pd.cut pour classer les valeurs dans les intervalles\n",
    "    classes = pd.cut(serie, bins=bins, labels=labels, right=False)\n",
    "    # Complete les valeurs manquantes (maximum de la serie) par la derniere borne\n",
    "    classes = classes.fillna(f\"[{bins[-2]};{bins[-1]}]\")\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FONCTION MAXI-BEST OF BIG MAC COCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On choisi 5 classes et un minimum de 10%\n",
    "def generate_classes(nb_classe,v_planche, serie) :\n",
    "    clef_repartition = clef_repartition_random(nb_classe,v_planche)\n",
    "    repartition_cumul = repartition_cumulative(clef_repartition,len(serie))\n",
    "    encadrement_classe = encadrements_classe(repartition_cumul, serie)\n",
    "    serie_finale = substitutions_valeurs1(serie,encadrement_classe)\n",
    "    return serie_finale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_classes(serie, df_income):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def khi2(df_classes, df_income):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        table = pd.crosstab(df_classes, df_income)\n",
    "        khi2, pval, ddl, contigent_theo = chi2_contingency(table)\n",
    "        return khi2, pval, ddl\n",
    "    \n",
    "    df_classes_min = generate_classes(6,5, serie)\n",
    "    khisq_min, pval_min, ddl_min = khi2(df_classes_min, df_income)\n",
    "    n=100000\n",
    "    deltas=[]\n",
    "\n",
    "    for i in range(n):\n",
    "        time1 = time.time()*1000\n",
    "        df_classes = generate_classes(6,5, serie)\n",
    "        time2 = time.time()*1000\n",
    "        deltas.append((time2-time1)/1000)\n",
    "        # print(i,'  Temps:', (deltas[-1]))\n",
    "        khisq, pval, ddl = khi2(df_classes, df_income)\n",
    "        if (khisq > khisq_min) and (pval<=pval_min):\n",
    "            conv = i\n",
    "            print(conv)\n",
    "            df_classes_min = df_classes\n",
    "            khisq_min = khisq\n",
    "            pval_min = pval\n",
    "            ddl_min = ddl\n",
    "    sum_delta = sum(deltas)\n",
    "    print('Temps total:', sum_delta, sum_delta/60)\n",
    "    print('Temps moyen pour une génération de table:', sum_delta/n)\n",
    "        \n",
    "    return df_classes_min, khisq_min, pval_min, ddl_min, conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(r'files\\clean.csv')\n",
    "\n",
    "# Isolation de la variable age pour faire les tests\n",
    "#df_income = df['income']\n",
    "#serie = df['age']\n",
    "\n",
    "# Ordonne la série dans l'ordre croissant et reinitialiser les index\n",
    "#serie = serie.sort_values()\n",
    "#serie = serie.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "6\n",
      "2464\n",
      "8239\n",
      "12161\n",
      "43211\n",
      "58408\n",
      "Temps total: 490.70199536132617 8.178366589355436\n",
      "Temps moyen pour une génération de table: 0.004907019953613262\n",
      "\n",
      " 0        [17;28[\n",
      "1        [17;28[\n",
      "2        [17;28[\n",
      "3        [17;28[\n",
      "4        [17;28[\n",
      "          ...   \n",
      "45217    [51;90]\n",
      "45218    [51;90]\n",
      "45219    [51;90]\n",
      "45220    [51;90]\n",
      "45221    [51;90]\n",
      "Name: age, Length: 45222, dtype: category\n",
      "Categories (6, object): ['[17;28[' < '[28;30[' < '[30;32[' < '[32;34[' < '[34;51[' < '[51;90]'] 11.370309495845198 0.04451256462694012 5 58408\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    df = pd.read_csv('files/clean.csv')\n",
    "    df_income = df['income']\n",
    "\n",
    "    serie = df['age']\n",
    "    serie = serie.sort_values()\n",
    "    serie = serie.reset_index(drop=True)\n",
    "\n",
    "    df_classes, khisq, pval, ddl, conv = optimize_classes(serie, df_income)\n",
    "    print(\"\\n\",df_classes, khisq, pval, ddl, conv)\n",
    "    df_classes.to_csv(f'files/classes_opti_THEO{df_classes.name}.csv', index=False)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "# passe la série en fichier csv\n",
    "# serie_finale.to_csv('classes_random_age_THEO.csv', index=False)\n",
    "\n",
    "# Met la serie original au coté de la serie finale pour vérifier les transformations effectuées\n",
    "# df_test_comparaison = pd.DataFrame({'age_1': serie_finale, 'age_2': serie})\n",
    "# df_test_comparaison.to_csv('classes_random_age_THEO.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
